{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pickle\n",
    "import spacy.cli\n",
    "\n",
    "spacy.cli.download(\"en_core_web_lg\")\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def load_wikipedia_to_dataframe(split='train'):\n",
    "    \"\"\"Load Wikipedia dataset and convert it to DataFrame.\"\"\"\n",
    "    dataset = load_dataset(\"wikipedia\", \"20220301.simple\", split=split)\n",
    "    df = pd.DataFrame(dataset)\n",
    "    return df\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def preprocess(text):\n",
    "    def remove_stopwords(text):\n",
    "        return [word for word in text if word not in stop_words]\n",
    "\n",
    "    def lemmatize(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "        doc = nlp(\" \".join(text))\n",
    "        return [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "\n",
    "    tokenized_text = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "    no_stopwords = remove_stopwords(tokenized_text)\n",
    "    lemmatized = lemmatize(no_stopwords)\n",
    "    return lemmatized\n",
    "\n",
    "def count_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return len(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/April</td>\n",
       "      <td>April</td>\n",
       "      <td>April is the fourth month of the year in the J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/August</td>\n",
       "      <td>August</td>\n",
       "      <td>August (Aug.) is the eighth month of the year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Art</td>\n",
       "      <td>Art</td>\n",
       "      <td>Art is a creative activity that expresses imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/A</td>\n",
       "      <td>A</td>\n",
       "      <td>A or a is the first letter of the English alph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Air</td>\n",
       "      <td>Air</td>\n",
       "      <td>Air refers to the Earth's atmosphere. Air is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                       url   title  \\\n",
       "0  1   https://simple.wikipedia.org/wiki/April   April   \n",
       "1  2  https://simple.wikipedia.org/wiki/August  August   \n",
       "2  6     https://simple.wikipedia.org/wiki/Art     Art   \n",
       "3  8       https://simple.wikipedia.org/wiki/A       A   \n",
       "4  9     https://simple.wikipedia.org/wiki/Air     Air   \n",
       "\n",
       "                                                text  \n",
       "0  April is the fourth month of the year in the J...  \n",
       "1  August (Aug.) is the eighth month of the year ...  \n",
       "2  Art is a creative activity that expresses imag...  \n",
       "3  A or a is the first letter of the English alph...  \n",
       "4  Air refers to the Earth's atmosphere. Air is a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_articles_df = load_wikipedia_to_dataframe()\n",
    "print(\"data loaded\")\n",
    "wiki_articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Filtering out texts with less than 8 sentences\n",
    "filtered_df = wiki_articles_df[wiki_articles_df['text'].apply(count_sentences) >= 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc09e8f1d4d4bd7905fc8658de42188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/70184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\swifter\\swifter.py:311\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[1;32m--> 311\u001b[0m     tmp_df \u001b[39m=\u001b[39m func(sample, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    312\u001b[0m     sample_df \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39mapply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Desktop\\Diplomatiki2\\AutoencoderCreation\\CreateDataset.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [token\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mpos_ \u001b[39min\u001b[39;00m allowed_postags]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m tokenized_text \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49msimple_preprocess(text, deacc\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m no_stopwords \u001b[39m=\u001b[39m remove_stopwords(tokenized_text)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\gensim\\utils.py:311\u001b[0m, in \u001b[0;36msimple_preprocess\u001b[1;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \n\u001b[0;32m    291\u001b[0m \u001b[39mUses :func:`~gensim.utils.tokenize` internally.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m tokens \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 311\u001b[0m     token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokenize(doc, lower\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, deacc\u001b[39m=\u001b[39;49mdeacc, errors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mignore\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    312\u001b[0m     \u001b[39mif\u001b[39;00m min_len \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(token) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m max_len \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m token\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    313\u001b[0m ]\n\u001b[0;32m    314\u001b[0m \u001b[39mreturn\u001b[39;00m tokens\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\gensim\\utils.py:262\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[0;32m    261\u001b[0m lowercase \u001b[39m=\u001b[39m lowercase \u001b[39mor\u001b[39;00m to_lower \u001b[39mor\u001b[39;00m lower\n\u001b[1;32m--> 262\u001b[0m text \u001b[39m=\u001b[39m to_unicode(text, encoding, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    263\u001b[0m \u001b[39mif\u001b[39;00m lowercase:\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\gensim\\utils.py:365\u001b[0m, in \u001b[0;36many2unicode\u001b[1;34m(text, encoding, errors)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m--> 365\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39;49m(text, encoding, errors\u001b[39m=\u001b[39;49merrors)\n",
      "\u001b[1;31mTypeError\u001b[0m: decoding to str: need a bytes-like object, Series found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Desktop\\Diplomatiki2\\AutoencoderCreation\\CreateDataset.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mswifter\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m filtered_df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mswifter\u001b[39m.\u001b[39;49mapply(preprocess)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Save the lemmatized_data as a pickle file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m filtered_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\swifter\\swifter.py:329\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parallel_apply(func, convert_dtype, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# use pandas\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pandas_apply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj, func, convert_dtype, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\swifter\\swifter.py:235\u001b[0m, in \u001b[0;36mSeriesAccessor._pandas_apply\u001b[1;34m(self, df, func, convert_dtype, *args, **kwds)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_bar:\n\u001b[0;32m    234\u001b[0m     tqdm\u001b[39m.\u001b[39mpandas(desc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_bar_desc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mPandas Apply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39mprogress_apply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39mapply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\tqdm\\std.py:920\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 920\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    921\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    922\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\pandas\\core\\series.py:4753\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   4755\u001b[0m         func,\n\u001b[0;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[0;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[0;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m   4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[0;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[0;32m   1289\u001b[0m )\n\u001b[0;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\tqdm\\std.py:915\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    910\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    913\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    914\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Desktop\\Diplomatiki2\\AutoencoderCreation\\CreateDataset.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m tokenized_text \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39msimple_preprocess(text, deacc\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m no_stopwords \u001b[39m=\u001b[39m remove_stopwords(tokenized_text)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m lemmatized \u001b[39m=\u001b[39m lemmatize(no_stopwords)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m lemmatized\n",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Desktop\\Diplomatiki2\\AutoencoderCreation\\CreateDataset.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(text, allowed_postags\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mNOUN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mADJ\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mVERB\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mADV\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(text))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Desktop/Diplomatiki2/AutoencoderCreation/CreateDataset.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [token\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mpos_ \u001b[39min\u001b[39;00m allowed_postags]\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\spacy\\language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:253\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:274\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\spacy\\ml\\tb_framework.py:33\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 33\u001b[0m     step_model \u001b[39m=\u001b[39m ParserStepModel(\n\u001b[0;32m     34\u001b[0m         X,\n\u001b[0;32m     35\u001b[0m         model\u001b[39m.\u001b[39;49mlayers,\n\u001b[0;32m     36\u001b[0m         unseen_classes\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39munseen_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     37\u001b[0m         train\u001b[39m=\u001b[39;49mis_train,\n\u001b[0;32m     38\u001b[0m         has_upper\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39mhas_upper\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     39\u001b[0m     )\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m step_model, step_model\u001b[39m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:213\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\layers\\concatenate.py:49\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 49\u001b[0m     Ys, callbacks \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[layer(X, is_train\u001b[39m=\u001b[39mis_train) \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers])\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Ys[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[0;32m     51\u001b[0m         data_l, backprop \u001b[39m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\layers\\concatenate.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 49\u001b[0m     Ys, callbacks \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[layer(X, is_train\u001b[39m=\u001b[39;49mis_train) \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers])\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Ys[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[0;32m     51\u001b[0m         data_l, backprop \u001b[39m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\layers\\list2ragged.py:26\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(InT, model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39munflatten(dYr\u001b[39m.\u001b[39mdata, dYr\u001b[39m.\u001b[39mlengths))\n\u001b[0;32m     25\u001b[0m lengths \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m Xs])\n\u001b[1;32m---> 26\u001b[0m \u001b[39mreturn\u001b[39;00m Ragged(model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mflatten(Xs), lengths), backprop\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\thinc\\backends\\ops.py:306\u001b[0m, in \u001b[0;36mOps.flatten\u001b[1;34m(self, X, dtype, pad, ndim_if_empty)\u001b[0m\n\u001b[0;32m    304\u001b[0m     padded\u001b[39m.\u001b[39mappend(xp\u001b[39m.\u001b[39mzeros((pad,) \u001b[39m+\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:], dtype\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdtype))\n\u001b[0;32m    305\u001b[0m     X \u001b[39m=\u001b[39m padded\n\u001b[1;32m--> 306\u001b[0m result \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39;49mconcatenate(X)\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m     result \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39masarray(result, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import swifter\n",
    "\n",
    "filtered_df['text'].swifter.apply(preprocess)\n",
    "# Save the lemmatized_data as a pickle file\n",
    "filtered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax: DataFrame.to_pickle(filepath)\n",
    "filtered_df.to_pickle(\"filtered_df.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
