{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>medoids</th>\n",
       "      <th>cluster_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.0019472323, 0.058371827, 0.0812831, 0.030...</td>\n",
       "      <td>[[-0.004593551, 0.051833656, -0.013445671, -0....</td>\n",
       "      <td>[10, 7, 9, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.01151042, -0.021297293, -0.004139077, 0.03...</td>\n",
       "      <td>[[0.004454516, 0.011180584, 0.053998474, -0.02...</td>\n",
       "      <td>[6, 2, 5, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>[[0.013927452, 0.035443924, 0.016817052, -0.01...</td>\n",
       "      <td>[[-0.0025131523, 0.072745346, 0.04038468, -0.0...</td>\n",
       "      <td>[2, 2, 2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>[[0.02544553, -0.03236037, 0.0035475865, 0.070...</td>\n",
       "      <td>[[-0.013504671, 0.07948076, 0.097698964, 0.042...</td>\n",
       "      <td>[2, 2, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>[[0.017213065, -0.013364788, 0.013486441, -0.0...</td>\n",
       "      <td>[[-0.0059717577, 0.035555597, 0.024298443, -0....</td>\n",
       "      <td>[3, 3, 1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15742</th>\n",
       "      <td>909992</td>\n",
       "      <td>[[-0.07872735, -0.009727927, 0.023001013, -0.0...</td>\n",
       "      <td>[[0.020977847, 0.00994313, 0.016100913, -0.020...</td>\n",
       "      <td>[3, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15743</th>\n",
       "      <td>910046</td>\n",
       "      <td>[[0.0024761495, 0.029174268, -0.121854655, 0.0...</td>\n",
       "      <td>[[-0.04889003, -0.027657501, -0.03703226, 0.00...</td>\n",
       "      <td>[3, 1, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15744</th>\n",
       "      <td>910075</td>\n",
       "      <td>[[-0.03798147, 0.0035953722, 0.03408878, 0.035...</td>\n",
       "      <td>[[0.011452884, 0.14479369, -0.02908832, 0.0719...</td>\n",
       "      <td>[3, 2, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15745</th>\n",
       "      <td>910092</td>\n",
       "      <td>[[-0.022506248, -0.034485348, -0.053791, 0.072...</td>\n",
       "      <td>[[-0.022506248, -0.034485348, -0.053791, 0.072...</td>\n",
       "      <td>[2, 1, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15746</th>\n",
       "      <td>910312</td>\n",
       "      <td>[[0.02741555, 0.07259655, -0.020830669, 0.0688...</td>\n",
       "      <td>[[-0.021110417, 0.13329503, 0.0009666801, -0.0...</td>\n",
       "      <td>[10, 13, 6, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15747 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          embedding  \\\n",
       "0           1  [[-0.0019472323, 0.058371827, 0.0812831, 0.030...   \n",
       "1           2  [[0.01151042, -0.021297293, -0.004139077, 0.03...   \n",
       "2           6  [[0.013927452, 0.035443924, 0.016817052, -0.01...   \n",
       "3           9  [[0.02544553, -0.03236037, 0.0035475865, 0.070...   \n",
       "4          13  [[0.017213065, -0.013364788, 0.013486441, -0.0...   \n",
       "...       ...                                                ...   \n",
       "15742  909992  [[-0.07872735, -0.009727927, 0.023001013, -0.0...   \n",
       "15743  910046  [[0.0024761495, 0.029174268, -0.121854655, 0.0...   \n",
       "15744  910075  [[-0.03798147, 0.0035953722, 0.03408878, 0.035...   \n",
       "15745  910092  [[-0.022506248, -0.034485348, -0.053791, 0.072...   \n",
       "15746  910312  [[0.02741555, 0.07259655, -0.020830669, 0.0688...   \n",
       "\n",
       "                                                 medoids   cluster_sizes  \n",
       "0      [[-0.004593551, 0.051833656, -0.013445671, -0....   [10, 7, 9, 1]  \n",
       "1      [[0.004454516, 0.011180584, 0.053998474, -0.02...    [6, 2, 5, 1]  \n",
       "2      [[-0.0025131523, 0.072745346, 0.04038468, -0.0...    [2, 2, 2, 4]  \n",
       "3      [[-0.013504671, 0.07948076, 0.097698964, 0.042...    [2, 2, 1, 1]  \n",
       "4      [[-0.0059717577, 0.035555597, 0.024298443, -0....    [3, 3, 1, 3]  \n",
       "...                                                  ...             ...  \n",
       "15742  [[0.020977847, 0.00994313, 0.016100913, -0.020...    [3, 1, 1, 1]  \n",
       "15743  [[-0.04889003, -0.027657501, -0.03703226, 0.00...    [3, 1, 2, 1]  \n",
       "15744  [[0.011452884, 0.14479369, -0.02908832, 0.0719...    [3, 2, 1, 1]  \n",
       "15745  [[-0.022506248, -0.034485348, -0.053791, 0.072...    [2, 1, 2, 1]  \n",
       "15746  [[-0.021110417, 0.13329503, 0.0009666801, -0.0...  [10, 13, 6, 6]  \n",
       "\n",
       "[15747 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataframe\n",
    "df = pd.read_pickle('augmented_data.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 384)\n",
      "Using cuda device\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 7s 16ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "  9/394 [..............................] - ETA: 5s - loss: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\anaconda3\\envs\\gensim\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 6s 15ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.0016 - val_loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18eff7b4b80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Convert medoids to list of numpy arrays\n",
    "medoids_list = df['medoids'].apply(lambda x: np.array(x))\n",
    "\n",
    "# Stack them into a single numpy array and convert to PyTorch tensor\n",
    "medoids_np = np.stack(medoids_list.to_numpy())\n",
    "print(medoids_np[0].shape)\n",
    "medoids_tensor = torch.FloatTensor(medoids_np)\n",
    "\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "latent_dim = 64\n",
    "timesteps = 4  # as there are 4 sentences\n",
    "input_dim = 384  # embedding dimension\n",
    "\n",
    "# Define Encoder\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "encoded = LSTM(latent_dim)(inputs)\n",
    "\n",
    "# Define Decoder\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "# Combine Encoder and Decoder into an Autoencoder model\n",
    "autoencoder = Model(inputs, decoded)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Create DataLoader using tf.data.Dataset\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data, val_data = train_test_split(medoids_np, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create tf.data.Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_data))\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_data))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)  # No need to shuffle validation data\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# Train the model\n",
    "autoencoder.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - 2s 4ms/step\n",
      "493/493 [==============================] - 1s 1ms/step\n",
      "(15747, 64)\n"
     ]
    }
   ],
   "source": [
    "def get_encoder(autoencoder):\n",
    "    \"\"\"\n",
    "    Extracts the encoder part of the autoencoder.\n",
    "\n",
    "    Parameters:\n",
    "    autoencoder (tf.keras.Model): The trained autoencoder model.\n",
    "\n",
    "    Returns:\n",
    "    tf.keras.Model: The encoder model.\n",
    "    \"\"\"\n",
    "    encoder = Model(inputs=autoencoder.input, outputs=autoencoder.layers[1].output)\n",
    "    return encoder\n",
    "\n",
    "# Load the best model\n",
    "autoencoder.load_weights('best_model.h5')\n",
    "\n",
    "# To get the reconstructed embeddings\n",
    "reconstructed_embeddings = autoencoder.predict(medoids_np)\n",
    "\n",
    "# Usage:\n",
    "encoder_model = get_encoder(autoencoder)\n",
    "# For example, to obtain the encoded representations of your data:\n",
    "encoded_data = encoder_model.predict(medoids_np)\n",
    "print(encoded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
