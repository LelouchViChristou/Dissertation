{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "metadata_file_path = 'arxiv-metadata-oai-snapshot.json'\n",
    "output_pickle_path = 'filtered_dataset.pkl'\n",
    "\n",
    "# Load existing metadata\n",
    "metadata_df = pd.read_json(metadata_file_path, lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Categories:\n",
      "['hep-ph' 'math.CO' 'cs.CG' 'physics.gen-ph' 'math.CA' 'math.FA'\n",
      " 'cond-mat.mes-hall' 'gr-qc' 'cond-mat.mtrl-sci' 'astro-ph' 'math.NT'\n",
      " 'math.AG' 'math.AT' 'hep-th' 'math.PR' 'hep-ex' 'nlin.PS'\n",
      " 'physics.chem-ph' 'q-bio.MN' 'math.NA' 'cond-mat.str-el'\n",
      " 'cond-mat.stat-mech' 'math.RA' 'physics.optics' 'physics.comp-ph'\n",
      " 'q-bio.PE' 'q-bio.CB' 'quant-ph' 'q-bio.QM' 'hep-lat' 'nucl-th' 'math.OA'\n",
      " 'math.QA' 'math-ph' 'math.MP' 'nlin.CD' 'physics.plasm-ph'\n",
      " 'physics.space-ph' 'nlin.SI' 'cs.IT' 'math.IT' 'cs.NE' 'cs.AI'\n",
      " 'physics.ed-ph' 'math.DG' 'cond-mat.soft' 'physics.pop-ph' 'cs.DS'\n",
      " 'math.CV' 'math.DS' 'physics.soc-ph' 'nucl-ex' 'math.RT' 'cond-mat.other'\n",
      " 'physics.flu-dyn' 'physics.data-an' 'cs.CE' 'cs.MS' 'cs.NA' 'math.GR'\n",
      " 'cond-mat.supr-con' 'math.AC' 'math.SG' 'cs.CC' 'math.KT' 'math.GT'\n",
      " 'math.AP' 'physics.class-ph' 'q-bio.OT' 'physics.bio-ph' 'q-bio.BM'\n",
      " 'nlin.CG' 'cs.DM' 'cs.LO' 'cond-mat.dis-nn' 'math.MG' 'physics.atom-ph'\n",
      " 'math.SP' 'math.ST' 'stat.TH' 'physics.ao-ph' 'physics.ins-det'\n",
      " 'q-fin.CP' 'q-fin.PR' 'physics.geo-ph' 'q-bio.NC' 'q-fin.RM' 'q-bio.SC'\n",
      " 'astro-ph.HE' 'math.OC' 'cs.CR' 'math.CT' 'math.LO' 'cs.NI' 'q-fin.GN'\n",
      " 'q-fin.ST' 'cs.LG' 'cs.PF' 'stat.ME' 'stat.AP' 'math.GM'\n",
      " 'physics.atm-clus' 'cs.SE' 'physics.acc-ph' 'math.GN' 'stat.CO'\n",
      " 'physics.hist-ph' 'cs.AR' 'cs.SC' 'physics.med-ph' 'stat.ML' 'cs.CY'\n",
      " 'cs.IR' 'q-bio.GN' 'cs.CV' 'math.HO' 'cs.OH' 'cs.DB' 'cs.DL' 'cs.HC'\n",
      " 'cs.PL' 'nlin.AO' 'cs.GT' 'cs.DC' 'cond-mat.quant-gas' 'cs.MA' 'cs.CL'\n",
      " 'q-fin.PM' 'cs.MM' 'astro-ph.EP' 'cs.RO' 'econ.EM' 'cs.ET' 'q-bio.TO'\n",
      " 'cs.GL' 'astro-ph.SR' 'astro-ph.CO' 'cs.FL' 'cs.OS' 'q-fin.TR'\n",
      " 'astro-ph.IM' 'cs.SD' 'cs.GR' 'cs.SY' 'astro-ph.GA' 'cs.SI' 'econ.TH'\n",
      " 'stat.OT' 'physics.app-ph' 'q-fin.EC' 'eess.SY' 'econ.GN' 'eess.IV'\n",
      " 'eess.AS' 'eess.SP' 'q-fin.MF' 'acc-phys' 'adap-org' 'q-bio' 'cond-mat'\n",
      " 'chao-dyn' 'patt-sol' 'dg-ga' 'solv-int' 'bayes-an' 'comp-gas' 'alg-geom'\n",
      " 'funct-an' 'q-alg' 'ao-sci' 'atom-ph' 'chem-ph' 'plasm-ph' 'mtrl-th'\n",
      " 'cmp-lg' 'supr-con']\n"
     ]
    }
   ],
   "source": [
    "# # Split the 'categories' column into lists\n",
    "# metadata_df['categories'] = metadata_df['categories'].str.split()\n",
    "\n",
    "# # Explode the DataFrame to have one category per row\n",
    "# exploded_df = metadata_df.explode('categories')\n",
    "\n",
    "# # Find and print all unique categories\n",
    "# unique_categories = exploded_df['categories'].unique()\n",
    "# print(\"Unique Categories:\")\n",
    "# print(unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique High-level Categories:\n",
      "{'econ', 'q-alg', 'alg-geom', 'nlin', 'q-bio', 'hep-ph', 'atom-ph', 'patt-sol', 'hep-lat', 'mtrl-th', 'solv-int', 'gr-qc', 'quant-ph', 'cs', 'chem-ph', 'comp-gas', 'nucl-th', 'ao-sci', 'chao-dyn', 'math', 'cmp-lg', 'cond-mat', 'astro-ph', 'plasm-ph', 'hep-th', 'stat', 'dg-ga', 'funct-an', 'eess', 'acc-phys', 'hep-ex', 'adap-org', 'nucl-ex', 'bayes-an', 'physics', 'q-fin', 'math-ph', 'supr-con'}\n"
     ]
    }
   ],
   "source": [
    "# Remove part after the dot and get unique high-level categories\n",
    "unique_high_level_categories = set(category.split('.')[0] for category in unique_categories if pd.notna(category))\n",
    "print(\"Unique High-level Categories:\")\n",
    "print(unique_high_level_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_primary_category\n",
      "math        392119\n",
      "cs          331262\n",
      "astro-ph    254712\n",
      "cond-mat    246311\n",
      "physics     109502\n",
      "hep-ph       79856\n",
      "quant-ph     65928\n",
      "hep-th       57766\n",
      "gr-qc        29569\n",
      "stat         24573\n",
      "nucl-th      19028\n",
      "hep-ex       17286\n",
      "q-bio        14758\n",
      "nlin         10294\n",
      "hep-lat       9991\n",
      "eess          9989\n",
      "nucl-ex       7376\n",
      "q-fin         5950\n",
      "econ          2052\n",
      "Name: count, dtype: int64\n",
      "Filtered data saved to filtered_dataset.pkl.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to extract unique primary categories from a single 'categories' string\n",
    "def get_unique_primary_categories(categories_str):\n",
    "    # Split on spaces to get individual categories\n",
    "    categories = categories_str.split(' ')\n",
    "    # Split on '.' to separate primary and sub-categories, and take the primary part\n",
    "    primary_categories = {category.split('.')[0] for category in categories}\n",
    "    return primary_categories\n",
    "\n",
    "# Apply the function to the 'categories' column\n",
    "metadata_df['unique_primary_categories'] = metadata_df['categories'].apply(get_unique_primary_categories)\n",
    "\n",
    "# Filter papers with only one unique_primary_category\n",
    "single_category_papers = metadata_df[metadata_df['unique_primary_categories'].apply(len) == 1]\n",
    "\n",
    "# Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "single_category_papers = single_category_papers.copy()\n",
    "\n",
    "# Now, to simplify further analysis, convert the set to a string\n",
    "single_category_papers['unique_primary_category'] = single_category_papers['unique_primary_categories'].apply(lambda x: list(x)[0])\n",
    "\n",
    "# Count the number of records in each unique_primary_category\n",
    "category_counts = single_category_papers['unique_primary_category'].value_counts()\n",
    "\n",
    "# Print the count of records in each unique_primary_category\n",
    "print(category_counts)\n",
    "\n",
    "# Select the desired columns\n",
    "selected_columns_df = single_category_papers[['id', 'title', 'doi', 'categories', 'unique_primary_category']]\n",
    "\n",
    "# Save the selected columns to a pickle file\n",
    "selected_columns_df.to_pickle(output_pickle_path)\n",
    "\n",
    "print(f'Filtered data saved to {output_pickle_path}.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-ph\\hep-ph_9301240.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-ph\\1010.5976.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-ph\\hep-ph_9302216.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:   5%|▌         | 1/19 [14:28<4:20:34, 868.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\physics\\2109.03600.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\physics\\physics_0001034.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\physics\\physics_0003032.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  11%|█         | 2/19 [42:07<6:17:46, 1333.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\math\\1703.01743.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\math\\2309.08677.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\math\\1501.02916.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\math\\1601.00956.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\math\\1209.2063.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  16%|█▌        | 3/19 [56:22<4:57:18, 1114.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\cond-mat\\2202.08110.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\cond-mat\\1701.08691.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\cond-mat\\cond-mat_9402069.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\cond-mat\\2005.01251.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  21%|██        | 4/19 [1:16:11<4:46:01, 1144.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\gr-qc\\gr-qc_9710115.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\gr-qc\\1208.5824.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\gr-qc\\1106.5296.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\gr-qc\\gr-qc_0610157.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\gr-qc\\gr-qc_9402029.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  26%|██▋       | 5/19 [1:31:06<4:06:03, 1054.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\astro-ph\\astro-ph_9707257.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\astro-ph\\astro-ph_9301010.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\astro-ph\\1403.0814.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  32%|███▏      | 6/19 [1:58:16<4:30:49, 1249.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-th\\0707.1382.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-th\\hep-th_9307070.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-th\\hep-th_0408153.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-th\\2309.00420.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-th\\1102.4058.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  42%|████▏     | 8/19 [2:29:08<3:18:12, 1081.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\nlin\\2307.14812.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\nlin\\1204.6637.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\nlin\\1506.07301.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  47%|████▋     | 9/19 [2:47:35<3:01:31, 1089.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\q-bio\\q-bio_0605026.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\q-bio\\2203.14201.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\q-bio\\1907.05529.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  53%|█████▎    | 10/19 [3:17:22<3:15:42, 1304.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\cs\\1309.7735.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\cs\\2310.02845.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  58%|█████▊    | 11/19 [3:47:49<3:15:17, 1464.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\nucl-th\\2104.07421.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\nucl-th\\nucl-th_0412036.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\nucl-th\\0911.5705.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  63%|██████▎   | 12/19 [4:02:51<2:30:53, 1293.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\quant-ph\\quant-ph_0202050.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\quant-ph\\1008.1521.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\quant-ph\\quant-ph_9911076.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  74%|███████▎  | 14/19 [4:41:56<1:42:51, 1234.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-lat\\hep-lat_9211054.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-lat\\hep-lat_9211026.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\hep-lat\\hep-lat_9211064.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  79%|███████▉  | 15/19 [4:55:41<1:14:03, 1110.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\stat\\1901.04312.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\stat\\2305.08235.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\stat\\1512.09325.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\stat\\1910.12925.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\stat\\2109.09339.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\stat\\1612.00099.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\stat\\1501.02469.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\stat\\1304.0150.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  84%|████████▍ | 16/19 [5:18:41<59:35, 1191.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\q-fin\\2008.00908.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\q-fin\\0911.3117.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\q-fin\\2202.03146.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\q-fin\\2112.10447.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  89%|████████▉ | 17/19 [5:37:22<39:00, 1170.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\eess\\2309.09859.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\eess\\2303.01672.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\eess\\2104.11316.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\eess\\2309.06909.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  95%|█████████▍| 18/19 [6:05:18<22:02, 1322.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\econ\\2305.11350.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\econ\\2305.14029.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\econ\\2202.06921.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\econ\\2203.15646.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\econ\\2005.05713.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\econ\\2112.10542.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\econ\\2008.10217.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to convert pdfs\\econ\\2209.12426.pdf to text: cannot open broken document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories: 100%|██████████| 19/19 [6:22:41<00:00, 1208.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data enrichment complete. Enriched dataset saved to enriched_dataset.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import fitz\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "input_pickle_path = 'filtered_dataset.pkl'\n",
    "output_csv_path = 'enriched_dataset.csv'\n",
    "pdf_folder = 'pdfs'\n",
    "\n",
    "# Load the DataFrame from the pickle file\n",
    "metadata_df = pd.read_pickle(input_pickle_path)\n",
    "\n",
    "# Get unique categories from the DataFrame\n",
    "unique_categories = metadata_df['unique_primary_category'].unique()\n",
    "\n",
    "# Ensure the PDF folder exists\n",
    "os.makedirs(pdf_folder, exist_ok=True)\n",
    "\n",
    "# Function to download PDF\n",
    "def download_pdf(paper_id, category):\n",
    "    pdf_url = f'https://export.arxiv.org/pdf/{paper_id}.pdf'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(pdf_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        paper_id = paper_id.replace('/', '_')\n",
    "        category_folder = os.path.join(pdf_folder, category)\n",
    "        os.makedirs(category_folder, exist_ok=True)\n",
    "        pdf_file_path = os.path.join(category_folder, f'{paper_id}.pdf')\n",
    "        with open(pdf_file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        return pdf_file_path\n",
    "    else:\n",
    "        print(f'Failed to retrieve {paper_id}')\n",
    "        return None\n",
    "\n",
    "def convert_pdf_to_text(pdf_file_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_file_path)\n",
    "        text = \"\"\n",
    "        for page_number in range(len(pdf_document)):\n",
    "            page = pdf_document.load_page(page_number)\n",
    "            text += page.get_text()\n",
    "        pdf_document.close()\n",
    "        return text\n",
    "    except fitz.fitz.FileDataError as e:\n",
    "        print(f'Failed to convert {pdf_file_path} to text: {e}')\n",
    "        return None \n",
    "\n",
    "# Initialize an empty list to collect data\n",
    "full_text_data = []\n",
    "\n",
    "# Main loop to process each category\n",
    "for category in tqdm(unique_categories, desc=\"Processing categories\"):\n",
    "    category_papers = metadata_df[metadata_df['unique_primary_category'] == category]\n",
    "    sampled_papers = category_papers.sample(n=500, random_state=1, replace=False)\n",
    "    \n",
    "    for index, row in tqdm(sampled_papers.iterrows(), total=sampled_papers.shape[0], desc=f\"Processing papers in {category}\", leave=False):\n",
    "        paper_id = row['id']\n",
    "        # print(f'Processing {paper_id}...')\n",
    "        \n",
    "        pdf_file_path = download_pdf(paper_id, category)\n",
    "        if pdf_file_path is None:\n",
    "            continue\n",
    "        \n",
    "        paper_text = convert_pdf_to_text(pdf_file_path)\n",
    "        \n",
    "        # Delete the PDF file after processing\n",
    "        os.remove(pdf_file_path)\n",
    "\n",
    "        enriched_paper_data = row.to_dict()\n",
    "        enriched_paper_data['full_text'] = paper_text\n",
    "        full_text_data.append(enriched_paper_data)\n",
    "\n",
    "# Create a new DataFrame with the enriched data\n",
    "enriched_data_df = pd.DataFrame(full_text_data)\n",
    "\n",
    "# Save the enriched data to a new CSV file\n",
    "enriched_data_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'Data enrichment complete. Enriched dataset saved to {output_csv_path}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>categories</th>\n",
       "      <th>unique_primary_category</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hep-ph/0610334</td>\n",
       "      <td>Weak interaction corrections to hadronic top q...</td>\n",
       "      <td>10.1103/PhysRevD.74.113005</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>arXiv:hep-ph/0610334v2  30 Nov 2006\\nPITHA 06/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2104.06416</td>\n",
       "      <td>Next-to-leading non-global logarithms in QCD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>Prepared for submission to JHEP\\nOUTP-21-08P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hep-ph/9606269</td>\n",
       "      <td>$K_L \\to \\pi^o \\nu \\overline{\\nu}$ in Extended...</td>\n",
       "      <td>10.1103/PhysRevD.54.4393</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>arXiv:hep-ph/9606269v3  27 Jun 1996\\nWM-96-105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hep-ph/9811382</td>\n",
       "      <td>A critical phenomenological study of inclusive...</td>\n",
       "      <td>10.1007/s100529900018</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>arXiv:hep-ph/9811382v1  18 Nov 1998\\nA CRITICA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1304.2781</td>\n",
       "      <td>Progress in the NNPDF global analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>arXiv:1304.2781v1  [hep-ph]  9 Apr 2013\\nEdinb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              title  \\\n",
       "0  hep-ph/0610334  Weak interaction corrections to hadronic top q...   \n",
       "1      2104.06416       Next-to-leading non-global logarithms in QCD   \n",
       "2  hep-ph/9606269  $K_L \\to \\pi^o \\nu \\overline{\\nu}$ in Extended...   \n",
       "3  hep-ph/9811382  A critical phenomenological study of inclusive...   \n",
       "4       1304.2781              Progress in the NNPDF global analysis   \n",
       "\n",
       "                          doi categories unique_primary_category  \\\n",
       "0  10.1103/PhysRevD.74.113005     hep-ph                  hep-ph   \n",
       "1                         NaN     hep-ph                  hep-ph   \n",
       "2    10.1103/PhysRevD.54.4393     hep-ph                  hep-ph   \n",
       "3       10.1007/s100529900018     hep-ph                  hep-ph   \n",
       "4                         NaN     hep-ph                  hep-ph   \n",
       "\n",
       "                                           full_text  \n",
       "0  arXiv:hep-ph/0610334v2  30 Nov 2006\\nPITHA 06/...  \n",
       "1  Prepared for submission to JHEP\\nOUTP-21-08P, ...  \n",
       "2  arXiv:hep-ph/9606269v3  27 Jun 1996\\nWM-96-105...  \n",
       "3  arXiv:hep-ph/9811382v1  18 Nov 1998\\nA CRITICA...  \n",
       "4  arXiv:1304.2781v1  [hep-ph]  9 Apr 2013\\nEdinb...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the enriched dataset from the CSV file\n",
    "enriched_data_df = pd.read_csv('enriched_dataset.csv')\n",
    "\n",
    "# Remove rows where the 'full_text' column is None or only whitespace\n",
    "cleaned_data_df = enriched_data_df[enriched_data_df['full_text'].apply(lambda x: bool(str(x).strip()))]\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_data_df.to_csv('cleaned_dataset_10k.csv', index=False)\n",
    "cleaned_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_primary_category\n",
      "astro-ph    500\n",
      "cond-mat    500\n",
      "cs          500\n",
      "econ        500\n",
      "eess        500\n",
      "gr-qc       500\n",
      "hep-ex      500\n",
      "hep-lat     500\n",
      "hep-ph      500\n",
      "hep-th      500\n",
      "math        500\n",
      "nlin        500\n",
      "nucl-ex     500\n",
      "nucl-th     500\n",
      "physics     500\n",
      "q-bio       500\n",
      "q-fin       500\n",
      "quant-ph    500\n",
      "stat        500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group by 'unique_primary_category' and get the count of records in each category\n",
    "category_counts = cleaned_data_df.groupby('unique_primary_category').size()\n",
    "\n",
    "# Print the count of records in each category\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           full_text  under_250_words\n",
      "0  arXiv:hep-ph/0610334v2  30 Nov 2006\\nPITHA 06/...            False\n",
      "1  Prepared for submission to JHEP\\nOUTP-21-08P, ...            False\n",
      "2  arXiv:hep-ph/9606269v3  27 Jun 1996\\nWM-96-105...            False\n",
      "3  arXiv:hep-ph/9811382v1  18 Nov 1998\\nA CRITICA...            False\n",
      "4  arXiv:1304.2781v1  [hep-ph]  9 Apr 2013\\nEdinb...            False\n",
      "Number of records with full text under 250 words: 70\n"
     ]
    }
   ],
   "source": [
    "def is_under_250_words(text):\n",
    "    word_count = len(str(text).split())\n",
    "    return word_count < 250\n",
    "\n",
    "# Apply the function to the 'full_text' column\n",
    "cleaned_data_df['under_250_words'] = cleaned_data_df['full_text'].apply(is_under_250_words)\n",
    "\n",
    "# Now 'under_250_words' column will have True if the full text is under 250 words, and False otherwise.\n",
    "# You can view the first few rows to check:\n",
    "print(cleaned_data_df[['full_text', 'under_250_words']].head())\n",
    "\n",
    "# If you want to get the count of records that are under 250 words:\n",
    "count_under_250 = cleaned_data_df['under_250_words'].sum()\n",
    "print(f'Number of records with full text under 250 words: {count_under_250}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First Few Rows of the Dataset:\n",
      "               id                                              title  \\\n",
      "0  hep-ph/0610334  Weak interaction corrections to hadronic top q...   \n",
      "1      2104.06416       Next-to-leading non-global logarithms in QCD   \n",
      "2  hep-ph/9606269  $K_L \\to \\pi^o \\nu \\overline{\\nu}$ in Extended...   \n",
      "3  hep-ph/9811382  A critical phenomenological study of inclusive...   \n",
      "4       1304.2781              Progress in the NNPDF global analysis   \n",
      "\n",
      "                          doi categories unique_primary_category  \\\n",
      "0  10.1103/PhysRevD.74.113005     hep-ph                  hep-ph   \n",
      "1                         NaN     hep-ph                  hep-ph   \n",
      "2    10.1103/PhysRevD.54.4393     hep-ph                  hep-ph   \n",
      "3       10.1007/s100529900018     hep-ph                  hep-ph   \n",
      "4                         NaN     hep-ph                  hep-ph   \n",
      "\n",
      "                                           full_text  full_text_length  \n",
      "0  arXiv:hep-ph/0610334v2  30 Nov 2006\\nPITHA 06/...             67463  \n",
      "1  Prepared for submission to JHEP\\nOUTP-21-08P, ...             85693  \n",
      "2  arXiv:hep-ph/9606269v3  27 Jun 1996\\nWM-96-105...             29912  \n",
      "3  arXiv:hep-ph/9811382v1  18 Nov 1998\\nA CRITICA...             55286  \n",
      "4  arXiv:1304.2781v1  [hep-ph]  9 Apr 2013\\nEdinb...             12628  \n",
      "\n",
      "Count of Unique Categories:\n",
      "290\n",
      "19\n",
      "\n",
      "Statistics about the Size of Full Text:\n",
      "count      1888.000000\n",
      "mean      46576.701801\n",
      "std       36077.280238\n",
      "min        1804.000000\n",
      "25%       22552.750000\n",
      "50%       37612.500000\n",
      "75%       58404.000000\n",
      "max      361967.000000\n",
      "Name: full_text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('testing/cleaned_dataset.csv')\n",
    "\n",
    "# Remove rows where full_text is NaN or empty\n",
    "df = df.dropna(subset=['full_text'])\n",
    "df = df[df['full_text'].str.strip() != '']\n",
    "\n",
    "# Calculate the length of each full_text entry\n",
    "df['full_text_length'] = df['full_text'].apply(len)\n",
    "\n",
    "\n",
    "# Print the first few rows of the dataset\n",
    "print(\"\\nFirst Few Rows of the Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Count the number of unique values in specific columns\n",
    "print(\"\\nCount of Unique Categories:\")\n",
    "print(df['categories'].nunique())\n",
    "print(df['unique_primary_category'].nunique())\n",
    "\n",
    "# Print statistics about the size of the full text\n",
    "print(\"\\nStatistics about the Size of Full Text:\")\n",
    "print(df['full_text_length'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
